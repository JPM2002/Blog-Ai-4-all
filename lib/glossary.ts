export const GLOSSARY = [
  { term: "softmax", short: "Transforms scores into probabilities that sum to 1." },
  { term: "self-attention", short: "Tokens attend to other tokens in the same sequence." },
  { term: "positional encoding", short: "Injects order info into token embeddings." },
  { term: "cross-entropy", short: "Loss measuring distance between predicted and true distributions." },
  { term: "backpropagation", short: "Algorithm to compute gradients through the network." },
  { term: "overfitting", short: "Model memorizes training data; poor generalization." },
  { term: "regularization", short: "Techniques that reduce overfitting (dropout, weight decay)." },
  { term: "gradient descent", short: "Iteratively updates parameters to minimize loss." },
]
